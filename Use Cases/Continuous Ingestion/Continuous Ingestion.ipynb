{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgJzHzDhcuJI"
   },
   "source": [
    "In this tutorial, we will guide you through the process of setting up an end-to-end continuously running workflow for the purposes of continuous ingestion of data.\n",
    "\n",
    "We will cover the following:\n",
    "\n",
    "- Preparing your dataset for synthetic data generation.\n",
    "- Utilizing Rockfish Recommendation Engine to automatically determine the most suitable model for training, along with key configurations and settings required for successful onboarding.\n",
    "- Generating and then evaluating synthetic data using the Rockfish Synthetic Data Assessor, which will help you improve the quality of your synthetic datasets.\n",
    "- Setting up an always on workflow using the settings generated from the onboarding process.\n",
    "- Applying custom labels to the models that are trained by the workflow.\n",
    "- Searching for a previously trained model in Rockfish's model store.\n",
    "- Using the model to generate synthetic data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72cj67zLabYj"
   },
   "source": [
    "### Install and Import Rockfish SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GUWjYJW7Vspw"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U 'rockfish[labs]' -f 'https://docs.rockfish.ai/packages/index.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I77DF8bPVx8j"
   },
   "outputs": [],
   "source": [
    "import rockfish as rf\n",
    "import rockfish.actions as ra\n",
    "from rockfish.labs.dataset_properties import (\n",
    "    DatasetPropertyExtractor,\n",
    "    FieldType,\n",
    "    EncoderType,\n",
    ")\n",
    "from rockfish.labs.steps import Recommender\n",
    "from rockfish.labs.metrics import marginal_dist_score\n",
    "from rockfish.labs.sda import SDA\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBGLOAALaZRt"
   },
   "source": [
    "### Connect to the Rockfish Platform\n",
    "\n",
    "❗❗ Replace API_KEY and API_URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_r56lqHPZfBT"
   },
   "outputs": [],
   "source": [
    "api_key = \"API_KEY\"\n",
    "\n",
    "conn = rf.Connection.remote(\"https://api.rockfish.ai\", api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Onboard the dataset onto Rockfish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fg-fmB4apMI"
   },
   "source": [
    "### Load the Dataset\n",
    "\n",
    "We support ingesting other data formats, refer documentation for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3foo29nQaf6U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730509525.955975 2571018 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-1.csv\n",
    "dataset = rf.Dataset.from_csv(\"finance\", \"finance-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "wa2qr_ZIfDrL",
    "outputId": "be8c88d2-de90-42f7-89b3-a673e0f7eb16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>fraud</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>35.13</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 00:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>27.63</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 08:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>13.46</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 16:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>28.86</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-02 00:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M151143676</td>\n",
       "      <td>barsandrestaurants</td>\n",
       "      <td>64.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-02 08:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8774</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>62.58</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-09 15:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-09 23:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>18.85</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-10 07:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>41.86</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-10 15:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>65.76</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-10 23:53:05.114045618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8779 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer age gender    merchant            category  amount  fraud  \\\n",
       "0      C100045114   4      M  M348934600      transportation   35.13      0   \n",
       "1      C100045114   4      M  M348934600      transportation   27.63      0   \n",
       "2      C100045114   4      M  M348934600      transportation   13.46      0   \n",
       "3      C100045114   4      M  M348934600      transportation   28.86      0   \n",
       "4      C100045114   4      M  M151143676  barsandrestaurants   64.99      0   \n",
       "...           ...  ..    ...         ...                 ...     ...    ...   \n",
       "8774  C1335108214   3      M  M348934600      transportation   62.58      0   \n",
       "8775  C1335108214   3      M  M348934600      transportation   11.99      0   \n",
       "8776  C1335108214   3      M  M348934600      transportation   18.85      0   \n",
       "8777  C1335108214   3      M  M348934600      transportation   41.86      0   \n",
       "8778  C1335108214   3      M  M348934600      transportation   65.76      0   \n",
       "\n",
       "                         timestamp  \n",
       "0    2023-01-01 00:00:00.000000000  \n",
       "1    2023-01-01 08:00:00.000000000  \n",
       "2    2023-01-01 16:00:00.000000000  \n",
       "3    2023-01-02 00:00:00.000000000  \n",
       "4    2023-01-02 08:00:00.000000000  \n",
       "...                            ...  \n",
       "8774 2023-01-09 15:53:05.114045618  \n",
       "8775 2023-01-09 23:53:05.114045618  \n",
       "8776 2023-01-10 07:53:05.114045618  \n",
       "8777 2023-01-10 15:53:05.114045618  \n",
       "8778 2023-01-10 23:53:05.114045618  \n",
       "\n",
       "[8779 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd4qldYKbRo_"
   },
   "source": [
    "### Onboard the dataset onto Rockfish\n",
    "\n",
    "The onboarding workflow is a good starting point to get to a synthetic version of your dataset quickly.\n",
    "\n",
    "To ensure optimal synthetic data generation, it's crucial to provide domain-specific information related to your dataset. This helps Rockfish’s Recommendation Engine tailor the workflow to your specific needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuvZsn7tbbI0",
    "outputId": "133f5554-15ca-4c29-dcc4-6938cb6ac00e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# _________________________________________________________________________\n",
      "#\n",
      "# RECOMMENDED CONFIGURATIONS\n",
      "#\n",
      "# (Remove or change any actions or configurations that are inappropriate\n",
      "#  for your use case, or add missing ones)\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n",
      "We detected a timeseries dataset with the following properties:\n",
      "Dimensions of dataset: (8779 x 8)\n",
      "Metadata fields: ['age', 'gender']\n",
      "Measurement fields: ['category', 'amount', 'merchant', 'fraud']\n",
      "Timestamp field: timestamp\n",
      "Session key field: customer\n",
      "Number of sessions: 658\n",
      "\n",
      "# _________________________________________________________________________\n",
      "#\n",
      "# ~~~~~ Pre-processing recommendations ~~~~~\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "# _________________________________________________________________________\n",
      "#\n",
      "# ~~~~~ Model recommendations ~~~~~\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n",
      "We recommend using the TimeGAN model.\n",
      "\n",
      "For training, we recommend the following model parameters:\n",
      "DGConfig(sample_len=1, activate_normalization_per_sample=True, generator_attribute_num_layers=5, generator_feature_num_layers=1, epoch=10, batch_size=16, g_lr=0.0001, d_lr=0.0001, attr_d_beta1=0.5, sessions=200, extras={})\n",
      "\n",
      "For generation, we recommend the following model parameters:\n",
      "sessions: 200\n",
      "\n",
      "# _________________________________________________________________________\n",
      "#\n",
      "# ~~~~~ Post-processing recommendations ~~~~~\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_properties = DatasetPropertyExtractor(\n",
    "    dataset,\n",
    "    session_key=\"customer\",\n",
    "    metadata_fields=[\"age\", \"gender\"],\n",
    "    additional_property_keys=[\"association_rules\"],\n",
    ").extract()\n",
    "recommender_output = Recommender(dataset_properties).run()\n",
    "print(recommender_output.report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQQOTUnxb6XJ"
   },
   "source": [
    "#### Run the recommended workflow to get a synthetic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4mY164eb9Ic",
    "outputId": "f7bcd58f-1d0c-4862-848c-169bee00b49a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow: 7hOPVXb0i0FM8kb4Z6SrVf\n"
     ]
    }
   ],
   "source": [
    "rec_actions = recommender_output.actions\n",
    "save = ra.DatasetSave({\"name\": \"synthetic\"})\n",
    "\n",
    "# use recommended actions in a Rockfish workflow\n",
    "builder = rf.WorkflowBuilder()\n",
    "builder.add_path(dataset, *rec_actions, save)\n",
    "\n",
    "# run the Rockfish workflow\n",
    "pre_workflow = await builder.start(conn)\n",
    "print(f\"Workflow: {pre_workflow.id()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6bScF8ncLN4"
   },
   "source": [
    "View logs for the running workflow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TeT2DFZcKj2",
    "outputId": "2c8df097-0640-4e90-caec-1c13fe77f36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02T01:05:27Z dataset-load: INFO Loading dataset '4RiOKAAJcbPQyuZ90BWIqF' with 8779 rows\n",
      "2024-11-02T01:05:27Z train-time-gan: WARN Unsafe time cast on timestamp\n",
      "2024-11-02T01:05:28Z train-time-gan: INFO Starting DG training job\n",
      "2024-11-02T01:05:31Z train-time-gan: INFO Epoch 1 completed.\n",
      "2024-11-02T01:05:35Z train-time-gan: INFO Epoch 2 completed.\n",
      "2024-11-02T01:05:39Z train-time-gan: INFO Epoch 3 completed.\n",
      "2024-11-02T01:05:42Z train-time-gan: INFO Epoch 4 completed.\n",
      "2024-11-02T01:05:46Z train-time-gan: INFO Epoch 5 completed.\n",
      "2024-11-02T01:05:49Z train-time-gan: INFO Epoch 6 completed.\n",
      "2024-11-02T01:05:53Z train-time-gan: INFO Epoch 7 completed.\n",
      "2024-11-02T01:05:57Z train-time-gan: INFO Epoch 8 completed.\n",
      "2024-11-02T01:06:00Z train-time-gan: INFO Epoch 9 completed.\n",
      "2024-11-02T01:06:04Z train-time-gan: INFO Epoch 10 completed.\n",
      "2024-11-02T01:06:06Z train-time-gan: INFO Training completed. Uploaded model a2e041c3-98b6-11ef-9a67-22aa4ec1349b\n",
      "2024-11-02T01:06:06Z generate-time-gan: INFO Downloading model with model_id='a2e041c3-98b6-11ef-9a67-22aa4ec1349b'...\n",
      "2024-11-02T01:06:07Z generate-time-gan: INFO Generating 200 sessions...\n",
      "2024-11-02T01:06:07Z dataset-save: INFO using field 'session_key' to concatenate tables\n",
      "2024-11-02T01:06:07Z dataset-save: INFO Saved dataset 'mo6FjUzTg7HUddiJJx0RN' with 3718 rows\n"
     ]
    }
   ],
   "source": [
    "async for log in pre_workflow.logs():\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEDizQAScg8J"
   },
   "source": [
    "Download and view the synthetic dataset locally:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "G4_0TVMncghE",
    "outputId": "5ac69b4c-d4db-46f8-9f6b-63264954afc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>fraud</th>\n",
       "      <th>session_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 21:03:45.274</td>\n",
       "      <td>5017.255356</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>M1823072687</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-06 08:18:59.735</td>\n",
       "      <td>4701.608062</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-06 21:14:20.711</td>\n",
       "      <td>4288.048567</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-07 11:20:16.057</td>\n",
       "      <td>4005.334858</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-08 01:53:06.147</td>\n",
       "      <td>3778.009436</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>2023-01-11 05:10:29.262</td>\n",
       "      <td>-25.121359</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>2023-01-11 13:50:43.573</td>\n",
       "      <td>-29.509062</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>2023-01-11 22:02:48.081</td>\n",
       "      <td>-31.650354</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>2023-01-12 05:44:28.499</td>\n",
       "      <td>-30.706333</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>2023-01-12 12:49:21.758</td>\n",
       "      <td>-33.464587</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3718 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp       amount age gender     merchant  \\\n",
       "0    2023-01-05 21:03:45.274  5017.255356   2      F  M1823072687   \n",
       "1    2023-01-06 08:18:59.735  4701.608062   2      F   M348934600   \n",
       "2    2023-01-06 21:14:20.711  4288.048567   2      F   M348934600   \n",
       "3    2023-01-07 11:20:16.057  4005.334858   2      F   M348934600   \n",
       "4    2023-01-08 01:53:06.147  3778.009436   2      F   M348934600   \n",
       "...                      ...          ...  ..    ...          ...   \n",
       "3713 2023-01-11 05:10:29.262   -25.121359   0      M   M348934600   \n",
       "3714 2023-01-11 13:50:43.573   -29.509062   0      M   M348934600   \n",
       "3715 2023-01-11 22:02:48.081   -31.650354   0      M   M348934600   \n",
       "3716 2023-01-12 05:44:28.499   -30.706333   0      M   M348934600   \n",
       "3717 2023-01-12 12:49:21.758   -33.464587   0      M   M348934600   \n",
       "\n",
       "            category  fraud  session_key  \n",
       "0     transportation      0          0.0  \n",
       "1     transportation      0          0.0  \n",
       "2     transportation      0          0.0  \n",
       "3     transportation      0          0.0  \n",
       "4     transportation      0          0.0  \n",
       "...              ...    ...          ...  \n",
       "3713  transportation      0        199.0  \n",
       "3714  transportation      0        199.0  \n",
       "3715  transportation      0        199.0  \n",
       "3716  transportation      0        199.0  \n",
       "3717  transportation      0        199.0  \n",
       "\n",
       "[3718 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn = await pre_workflow.datasets().last()\n",
    "syn = await syn.to_local(conn)\n",
    "syn.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmhdoeldtI00"
   },
   "source": [
    "### Evaluate the synthetic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "form",
    "id": "vmngYsA7cTBo"
   },
   "outputs": [],
   "source": [
    "# @title ##### Define a helper function `get_fidelity_score()` to calculate the marginal distribution score:\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "def get_fidelity_score(source, source_dataset_properties, syn):\n",
    "    source = copy.deepcopy(source)\n",
    "    syn = copy.deepcopy(syn)\n",
    "\n",
    "    columns_to_drop = [source_dataset_properties.session_key]\n",
    "    source.table = source.table.drop_columns(columns_to_drop)\n",
    "\n",
    "    columns_to_drop = [\"session_key\"]\n",
    "    syn.table = syn.table.drop_columns(columns_to_drop)\n",
    "\n",
    "    categorical_measurements = source_dataset_properties.filter_fields(\n",
    "        ftype=FieldType.MEASUREMENT, etype=EncoderType.CATEGORICAL\n",
    "    )\n",
    "\n",
    "    return marginal_dist_score(\n",
    "        source,\n",
    "        syn,\n",
    "        metadata=source_dataset_properties.metadata_fields,\n",
    "        other_categorical=categorical_measurements,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNMp4sEeq2oT",
    "outputId": "6e2a69f5-5104-4692-c4ab-e02d6f08a114"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6394508595969407"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fidelity_score(\n",
    "    source=dataset, source_dataset_properties=dataset_properties, syn=syn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the actions look good, we can use them for setting up the always-on workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rockfish.actions.dg.TrainTimeGAN at 0x13714e7e0>,\n",
       " <rockfish.actions.dg.GenerateTimeGAN at 0x1078cd790>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_actions = rec_actions[:-1]\n",
    "generate_actions = rec_actions[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set up an always-on workflow for continuous data ingestion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employ the DataStreamLoad action to keep the workflow always on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion Workflow ID: BFzmU53Fdt9heeFeTgAOw\n"
     ]
    }
   ],
   "source": [
    "# reduce the batch size for the following ingested data stream as the batch\n",
    "# size should be smaller than the number of sessions in the dataset\n",
    "train_actions[0].config().doppelganger.batch_size = 14\n",
    "stream = ra.DatastreamLoad()\n",
    "\n",
    "builder = rf.WorkflowBuilder()\n",
    "builder.add(stream, alias=\"input\")\n",
    "builder.add_path(*train_actions, parents=[\"input\"], alias=\"train_actions\")\n",
    "ingest_workflow = await builder.start(conn)\n",
    "print(f\"Ingestion Workflow ID: {ingest_workflow.id()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the data files to the workflow stream\n",
    "\n",
    "- each input is a dataset\n",
    "- each output is a trained model stored to the model_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data files to the workflow stream\n",
    "\n",
    "Replace the workflow ID with the actual workflow ID of the workflow that was set up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the sample files for the datastream workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730509572.085200 2571018 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730509572.353754 2571018 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730509572.588498 2571018 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-2.csv\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-3.csv\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the workflow ID with the ID of the workflow that was just set up.\n",
    "\n",
    "This also allows you to run the data-ingestion service in an independent process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the workflow with the previous ID without need to re-build the workflow\n",
    "workflow_id = ingest_workflow.id()  # insert workflow ID here\n",
    "workflow = await conn.get_workflow(workflow_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing finance-2 to datastream...\n",
      "Writing finance-3 to datastream...\n",
      "Writing finance-4 to datastream...\n"
     ]
    }
   ],
   "source": [
    "for file_num in range(2, 5):\n",
    "    data = rf.Dataset.from_csv(\"finance\", f\"finance-{file_num}.csv\")\n",
    "    await workflow.write_datastream(\n",
    "        \"input\", data\n",
    "    )  # \"input\" is the pre-set alias of the datastream\n",
    "    print(f\"Writing finance-{file_num} to datastream...\")\n",
    "    time.sleep(10)\n",
    "await workflow.close_datastream(\n",
    "    \"input\"\n",
    ")  # \"input\" is the pre-set alias of the datastream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02T01:06:14Z train_actions: WARN Unsafe time cast on timestamp\n",
      "2024-11-02T01:06:15Z train_actions: INFO Starting DG training job\n",
      "2024-11-02T01:06:19Z train_actions: INFO Epoch 1 completed.\n",
      "2024-11-02T01:06:23Z train_actions: INFO Epoch 2 completed.\n",
      "2024-11-02T01:06:14Z input: INFO Read batch with 8850 rows from datastream\n",
      "2024-11-02T01:06:25Z input: INFO Read batch with 9080 rows from datastream\n",
      "2024-11-02T01:06:27Z train_actions: INFO Epoch 3 completed.\n",
      "2024-11-02T01:06:35Z input: INFO Read batch with 6979 rows from datastream\n",
      "2024-11-02T01:06:31Z train_actions: INFO Epoch 4 completed.\n",
      "2024-11-02T01:06:35Z train_actions: INFO Epoch 5 completed.\n",
      "2024-11-02T01:06:39Z train_actions: INFO Epoch 6 completed.\n",
      "2024-11-02T01:06:43Z train_actions: INFO Epoch 7 completed.\n",
      "2024-11-02T01:06:47Z train_actions: INFO Epoch 8 completed.\n",
      "2024-11-02T01:06:51Z train_actions: INFO Epoch 9 completed.\n",
      "2024-11-02T01:06:56Z train_actions: INFO Epoch 10 completed.\n",
      "2024-11-02T01:06:57Z train_actions: INFO Training completed. Uploaded model c1d17303-98b6-11ef-9a67-22aa4ec1349b\n",
      "2024-11-02T01:06:58Z train_actions: WARN Unsafe time cast on timestamp\n",
      "2024-11-02T01:06:58Z train_actions: INFO Starting DG training job\n",
      "2024-11-02T01:06:59Z train_actions: INFO Epoch 1 completed.\n",
      "2024-11-02T01:06:59Z train_actions: INFO Epoch 2 completed.\n",
      "2024-11-02T01:06:59Z train_actions: INFO Epoch 3 completed.\n",
      "2024-11-02T01:07:00Z train_actions: INFO Epoch 4 completed.\n",
      "2024-11-02T01:07:00Z train_actions: INFO Epoch 5 completed.\n",
      "2024-11-02T01:07:00Z train_actions: INFO Epoch 6 completed.\n",
      "2024-11-02T01:07:00Z train_actions: INFO Epoch 7 completed.\n",
      "2024-11-02T01:07:01Z train_actions: INFO Epoch 8 completed.\n",
      "2024-11-02T01:07:01Z train_actions: INFO Epoch 9 completed.\n",
      "2024-11-02T01:07:01Z train_actions: INFO Epoch 10 completed.\n",
      "2024-11-02T01:07:23Z train_actions: INFO Training completed. Uploaded model cf86092d-98b6-11ef-9a67-22aa4ec1349b\n",
      "2024-11-02T01:07:24Z train_actions: WARN Unsafe time cast on timestamp\n",
      "2024-11-02T01:07:24Z train_actions: INFO Starting DG training job\n",
      "2024-11-02T01:07:25Z train_actions: INFO Epoch 1 completed.\n",
      "2024-11-02T01:07:25Z train_actions: INFO Epoch 2 completed.\n",
      "2024-11-02T01:07:25Z train_actions: INFO Epoch 3 completed.\n",
      "2024-11-02T01:07:25Z train_actions: INFO Epoch 4 completed.\n",
      "2024-11-02T01:07:26Z train_actions: INFO Epoch 5 completed.\n",
      "2024-11-02T01:07:26Z train_actions: INFO Epoch 6 completed.\n",
      "2024-11-02T01:07:26Z train_actions: INFO Epoch 7 completed.\n",
      "2024-11-02T01:07:26Z train_actions: INFO Epoch 8 completed.\n",
      "2024-11-02T01:07:26Z train_actions: INFO Epoch 9 completed.\n",
      "2024-11-02T01:07:27Z train_actions: INFO Epoch 10 completed.\n",
      "2024-11-02T01:07:41Z train_actions: INFO Training completed. Uploaded model da7b689e-98b6-11ef-9a67-22aa4ec1349b\n"
     ]
    }
   ],
   "source": [
    "# check the status of the workflow\n",
    "async for log in workflow.logs():\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Add custom labels to the models that are generated\n",
    "\n",
    "These labels can be used later to filter models based off custom parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = [\"experimental\", \"staging\", \"production\"]\n",
    "i = 0\n",
    "async for model in conn.list_models(labels={\"workflow_id\": workflow_id}):\n",
    "    await model.add_labels(conn, usage=usage[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate synthetic data using the trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide query params to the model_store search to get appropriate models as response\n",
    "\n",
    "This can be used if the models trained were previously tagged, the default label that exists is 'workflow_id' which is the id of the workflow that trained the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='2cdd3986-98b0-11ef-a2bf-7af83af06a78', labels={'usage': 'production', 'workflow_id': '6piKEAAJARevbodbSUIzMf'}, create_time=datetime.datetime(2024, 11, 2, 0, 19, 50, tzinfo=datetime.timezone.utc), size_bytes=256840192)\n",
      "Model(id='2108ac09-98b5-11ef-9a67-22aa4ec1349b', labels={'usage': 'production', 'workflow_id': '6PynH6YbcdNT6AzqOUcj4M'}, create_time=datetime.datetime(2024, 11, 2, 0, 55, 18, tzinfo=datetime.timezone.utc), size_bytes=256840192)\n",
      "Model(id='347fa99a-98b6-11ef-a2bf-7af83af06a78', labels={'usage': 'production', 'workflow_id': '6W6Mls8b0Q7wc3zCTMYOVD'}, create_time=datetime.datetime(2024, 11, 2, 1, 3, tzinfo=datetime.timezone.utc), size_bytes=256835072)\n",
      "Model(id='da7b689e-98b6-11ef-9a67-22aa4ec1349b', labels={'usage': 'production', 'workflow_id': 'BFzmU53Fdt9heeFeTgAOw'}, create_time=datetime.datetime(2024, 11, 2, 1, 7, 38, tzinfo=datetime.timezone.utc), size_bytes=171769856)\n",
      "Model(id='c00744e0-98a8-11ef-a2bf-7af83af06a78', labels={'usage': 'production', 'workflow_id': '3S0ArPDbXDAD5cNeF9cnlJ'}, create_time=datetime.datetime(2024, 11, 1, 23, 26, 41, tzinfo=datetime.timezone.utc), size_bytes=209343488)\n"
     ]
    }
   ],
   "source": [
    "async for model in conn.list_models(labels={\"usage\": \"production\"}):\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model from the list of queried models and fetch it from remote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='c00744e0-98a8-11ef-a2bf-7af83af06a78', labels={'usage': 'production', 'workflow_id': '3S0ArPDbXDAD5cNeF9cnlJ'}, create_time=datetime.datetime(2024, 11, 1, 23, 26, 41, tzinfo=datetime.timezone.utc), size_bytes=209343488)\n"
     ]
    }
   ],
   "source": [
    "model = await rf.Model.from_id(\n",
    "    conn,\n",
    "    model.id,  # insert model id here of the filtered model after querying\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide the model and the synthesis config to a workflow to generate a synthetic dataset as the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow ID: 4P0fla7gp6MU85Tqx5DuyQ\n"
     ]
    }
   ],
   "source": [
    "builder = rf.WorkflowBuilder()\n",
    "builder.add(model)\n",
    "builder.add(*generate_actions, parents=[model], alias=\"gen\")\n",
    "builder.add(ra.DatasetSave(name=\"syn_data\"), parents=[\"gen\"])\n",
    "workflow = await builder.start(conn)\n",
    "print(f\"Workflow ID: {workflow.id()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02T01:10:13Z dataset-save: INFO using field 'session_key' to concatenate tables\n",
      "2024-11-02T01:10:13Z dataset-save: INFO Saved dataset 'BC4sYkI65pgGwZ2QctElx' with 35068 rows\n",
      "2024-11-02T01:09:58Z gen: INFO Downloading model with model_id='c00744e0-98a8-11ef-a2bf-7af83af06a78'...\n",
      "2024-11-02T01:10:11Z gen: INFO Generating 200 sessions...\n"
     ]
    }
   ],
   "source": [
    "async for log in workflow.logs():\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>fraud</th>\n",
       "      <th>session_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-06 23:59:38.418</td>\n",
       "      <td>5163.387593</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>M1946091778</td>\n",
       "      <td>fashion</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-07 20:43:36.007</td>\n",
       "      <td>6987.574420</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M732195782</td>\n",
       "      <td>leisure</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-06 00:13:24.170</td>\n",
       "      <td>1.165829</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>M349281107</td>\n",
       "      <td>contents</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-07 07:06:30.770</td>\n",
       "      <td>4697.402428</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>M480139044</td>\n",
       "      <td>wellnessandbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06 13:44:56.971</td>\n",
       "      <td>106.728580</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>M349281107</td>\n",
       "      <td>wellnessandbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>2023-01-07 01:01:53.614</td>\n",
       "      <td>403.839851</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>M2122776122</td>\n",
       "      <td>hyper</td>\n",
       "      <td>0</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35064</th>\n",
       "      <td>2023-01-06 04:17:57.393</td>\n",
       "      <td>6550.755616</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>M1649169323</td>\n",
       "      <td>wellnessandbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35065</th>\n",
       "      <td>2023-01-06 06:36:17.908</td>\n",
       "      <td>6514.552014</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>M1649169323</td>\n",
       "      <td>leisure</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35066</th>\n",
       "      <td>2023-01-06 08:54:38.501</td>\n",
       "      <td>6511.151229</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>M1649169323</td>\n",
       "      <td>wellnessandbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>2023-01-07 00:33:54.034</td>\n",
       "      <td>3425.767440</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M349281107</td>\n",
       "      <td>contents</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35068 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp       amount age gender     merchant  \\\n",
       "0     2023-01-06 23:59:38.418  5163.387593   5      M  M1946091778   \n",
       "1     2023-01-07 20:43:36.007  6987.574420   4      M   M732195782   \n",
       "2     2023-01-06 00:13:24.170     1.165829   0      E   M349281107   \n",
       "3     2023-01-07 07:06:30.770  4697.402428   1      F   M480139044   \n",
       "4     2023-01-06 13:44:56.971   106.728580   5      M   M349281107   \n",
       "...                       ...          ...  ..    ...          ...   \n",
       "35063 2023-01-07 01:01:53.614   403.839851   2      F  M2122776122   \n",
       "35064 2023-01-06 04:17:57.393  6550.755616   0      E  M1649169323   \n",
       "35065 2023-01-06 06:36:17.908  6514.552014   0      E  M1649169323   \n",
       "35066 2023-01-06 08:54:38.501  6511.151229   0      E  M1649169323   \n",
       "35067 2023-01-07 00:33:54.034  3425.767440   0      M   M349281107   \n",
       "\n",
       "                category  fraud  session_key  \n",
       "0                fashion      1          0.0  \n",
       "1                leisure      1          1.0  \n",
       "2               contents      1          2.0  \n",
       "3      wellnessandbeauty      0          3.0  \n",
       "4      wellnessandbeauty      0          4.0  \n",
       "...                  ...    ...          ...  \n",
       "35063              hyper      0        197.0  \n",
       "35064  wellnessandbeauty      0        198.0  \n",
       "35065            leisure      0        198.0  \n",
       "35066  wellnessandbeauty      0        198.0  \n",
       "35067           contents      0        199.0  \n",
       "\n",
       "[35068 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_data = await workflow.datasets().concat(conn)\n",
    "syn_data.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
