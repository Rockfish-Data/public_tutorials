{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d5a34-a445-479a-b188-49bb643cb682",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "language": "python",
    "name": "INSTALL_ROCKFISH_SDK"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install -U 'rockfish[labs]' -f 'https://packages.rockfish.ai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed189a7-8a07-448d-b86a-4b16f78cf517",
   "metadata": {
    "language": "python",
    "name": "READ_SOURCE_DATA_FROM_SNOWFLAKE"
   },
   "outputs": [],
   "source": [
    "# READ DATA FROM SNOWFLAKE TABLE\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "# The table you want to read\n",
    "TARGET_TABLE_FULL = '<DATABASE>.<SCHEMA>.<TABLE_NAME>'\n",
    "\n",
    "try:\n",
    "    # --- 1. Get Active Snowpark Session ---\n",
    "    print(\"Getting active Snowpark session...\")\n",
    "    session = get_active_session()\n",
    "\n",
    "    # --- 2. Create Snowpark DataFrame ---\n",
    "    print(f\"Creating Snowpark DataFrame for table: {TARGET_TABLE_FULL}\")\n",
    "    snowpark_df = session.table(TARGET_TABLE_FULL)\n",
    "\n",
    "    df_to_convert = snowpark_df\n",
    "    \n",
    "    # --- 4. Convert to Pandas DataFrame ---\n",
    "    print(\"Converting Snowpark DataFrame to pandas DataFrame...\")\n",
    "    # This executes the query and pulls data into the notebook's memory\n",
    "    df = df_to_convert.to_pandas()\n",
    "    print(f\"Successfully fetched {len(df)} rows into pandas DataFrame.\")\n",
    "    print(\"DataFrame Head:\")\n",
    "    print(df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # Handle potential SnowparkSQLException, permission errors etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62186ce-8b27-45c4-9b5d-344fc440562f",
   "metadata": {
    "language": "python",
    "name": "ONBOARD_TRAIN_GENERATE"
   },
   "outputs": [],
   "source": [
    "# Rockfish Environment Key & API URL\n",
    "import rockfish as rf\n",
    "import rockfish.actions as ra\n",
    "import rockfish.labs as rl\n",
    "import asyncio\n",
    "\n",
    "runner = asyncio\n",
    "\n",
    "api_key = \"<YOUR_API_KEY>\"\n",
    "api_url = \"https://api.rockfish.ai\"\n",
    "%env ROCKFISH_API_KEY=api_key\n",
    "async def start_rockfish():\n",
    "    conn = rf.Connection.remote(api_url, api_key)\n",
    "\n",
    "    #Onboard\n",
    "    # Perform any necessary feature engineering or preprocessing\n",
    "    dataset = rf.Dataset.from_pandas(\"<DATASET_NAME>\",df)\n",
    "    \n",
    "    categorical_fields = (\n",
    "        df.select_dtypes(include=[\"object\"]).columns\n",
    "    )\n",
    "    print(categorical_fields)\n",
    "    \n",
    "    config = {\n",
    "        \"encoder\": {\n",
    "            \"metadata\": [\n",
    "                {\"field\": field, \"type\": \"categorical\"}\n",
    "                for field in categorical_fields\n",
    "            ]\n",
    "            + [\n",
    "                {\"field\": field, \"type\": \"continuous\"}\n",
    "                for field in dataset.table.column_names\n",
    "                if field not in categorical_fields\n",
    "            ],\n",
    "        },\n",
    "        \"tabular-gan\": {\n",
    "            \"epochs\": 10,\n",
    "            \"records\": 10000,\n",
    "        }\n",
    "    }\n",
    "    print(dataset.table.column_names)\n",
    "\n",
    "    #Train\n",
    "    train = ra.TrainTabGAN(config)\n",
    "    \n",
    "    builder = rf.WorkflowBuilder()\n",
    "    builder.add_dataset(dataset)\n",
    "    builder.add_action(train, parents=[dataset])\n",
    "    workflow = await builder.start(conn)\n",
    "    print(f\"Training - Workflow: {workflow.id()}\")\n",
    "    \n",
    "    async for log in workflow.logs():\n",
    "        print(log) \n",
    "    \n",
    "    model = await workflow.models().nth(0)\n",
    "    await model.add_labels(conn)\n",
    "    #model\n",
    "\n",
    "    #Generate\n",
    "    generate = ra.GenerateTabGAN(config)\n",
    "    save = ra.DatasetSave({\"name\": \"synthetic\"})\n",
    "    builder = rf.WorkflowBuilder()\n",
    "    builder.add_model(model)\n",
    "    builder.add_action(generate, parents=[model])\n",
    "    builder.add_action(save, parents=[generate])\n",
    "    workflow = await builder.start(conn)\n",
    "    print(f\"Generate - Workflow: {workflow.id()}\")\n",
    "    \n",
    "    syn = None\n",
    "    async for sds in workflow.datasets():\n",
    "        syn = await sds.to_local(conn)\n",
    "    \n",
    "    return syn\n",
    "syn_data = runner.run(start_rockfish())\n",
    "\n",
    "import csv\n",
    "\n",
    "syn_data_pandas = syn_data.to_pandas()\n",
    "\n",
    "syn_data_pandas.to_csv(f\"synthetic_demo.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
    "print(\"VVVVVVVVVVVVVVVVVVVVVVVVVVVVV\")\n",
    "print(\"VVV Sample Synthetic Data VVV\")\n",
    "print(\"VVVVVVVVVVVVVVVVVVVVVVVVVVVVV\")\n",
    "syn_data_pandas.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e888876c-be49-4d5b-865a-62c4c17283b4",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "language": "python",
    "name": "SYNTHETIC_DATA_ASSESOR"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "dataset = rf.Dataset.from_pandas(\"<DATASET_NAME>\",df)\n",
    "\n",
    "for col in dataset.table.column_names:\n",
    "    source_agg = rf.metrics.count_all(dataset, col, nlargest=10)\n",
    "    syn_agg = rf.metrics.count_all(syn_data, col, nlargest=10)\n",
    "    rl.vis.plot_bar([source_agg, syn_agg], col, f\"{col}_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66b392-977f-4ca2-a2ed-521c489fa4fe",
   "metadata": {
    "language": "python",
    "name": "LIST_FILE"
   },
   "outputs": [],
   "source": [
    "!ls /home/app/synthetic_demo.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948546f-3a8d-455b-b2a7-f01bf8454913",
   "metadata": {
    "language": "sql",
    "name": "CREATE_STAGE"
   },
   "outputs": [],
   "source": [
    "--TRUNCATE TABLE ROCKFISHDATADEMO.ROCKFISHDATADEMO.SYNTHETIC_RF_DEMO\n",
    "CREATE OR REPLACE STAGE ROCKFISHDATADEMO.ROCKFISHDATADEMO.ROCKFISH_STAGE\n",
    "    COMMENT = 'Stage for Rockfish demo data';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1bb7d-007d-4ec3-b7b4-fd9bdc22714e",
   "metadata": {
    "language": "python",
    "name": "LOAD_RESULTS_TO_SNOWFALKE_STAGE"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "!ls /home/app/synthetic_rf_demo.csv\n",
    "\n",
    "notebook_file_path_str = '/home/app/synthetic_demo.csv'\n",
    "target_stage = '@<DESTINATION_DATABASE>.<DESTINATION_SCHEMA>.<DESTINATION_STAGE_NAME>'\n",
    "\n",
    "print(f\"File found at: {notebook_file_path_str}\")\n",
    "# --- Prepare and Execute PUT command ---\n",
    "file_uri = f\"file://{str(notebook_file_path_str)}\"\n",
    "put_sql = f\"PUT '{file_uri}' '{target_stage}' AUTO_COMPRESS=TRUE OVERWRITE=TRUE\"\n",
    "print(f\"Executing via Snowpark session: {put_sql}\")\n",
    "\n",
    "# Execute and fetch results correctly using Snowpark/connector methods\n",
    "put_results = session.sql(put_sql).collect()\n",
    "\n",
    "print(\"PUT command executed successfully.\")\n",
    "print(\"Results:\")\n",
    "for row in put_results:\n",
    "    print(row) # Connector handles getting status correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056beea-c4ed-49ac-99dc-190c9a230085",
   "metadata": {
    "language": "sql",
    "name": "TRUNCATE_TABLE_AND_COUNT"
   },
   "outputs": [],
   "source": [
    "TRUNCATE TABLE <DESTINATION_DATABASE>.<DESTINATION_SCHEMA>.<DESTINATION_SYNTHETIC_DATA_TABLE_NAME>;\n",
    "\n",
    "SELECT COUNT(*) FROM <DESTINATION_DATABASE>.<DESTINATION_SCHEMA>.<DESTINATION_SYNTHETIC_DATA_TABLE_NAME>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7bbebc-0b6b-4136-af01-3f127a7ec571",
   "metadata": {
    "language": "sql",
    "name": "COPY_SYNTHETIC_DATA_INTO_SNOWFLAKETABLE"
   },
   "outputs": [],
   "source": [
    "COPY INTO <DESTINATION_DATABASE>.<DESTINATION_SCHEMA>.<DESTINATION_SYNTHETIC_DATA_TABLE_NAME>\n",
    "FROM '@\"<DESTINATION_DATABASE>\".\"<DESTINATION_SCHEMA>\".\"<DESTINATION_STAGE_NAME>\"/synthetic_demo.csv.gz' -- Reference the file in the user stage (note .gz)\n",
    "FILE_FORMAT = ( -- YOU MUST DEFINE THE FILE FORMAT\n",
    "    TYPE = CSV\n",
    "    FIELD_DELIMITER = ','\n",
    "    SKIP_HEADER = 1 -- Adjust if your CSV has no header\n",
    "    EMPTY_FIELD_AS_NULL = TRUE\n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    ")\n",
    "ON_ERROR = 'CONTINUE'; -- Or other error handling options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8915b43-7df7-4b55-a5c0-ada5d42aeaa6",
   "metadata": {
    "language": "sql",
    "name": "COUNT_ROWS_IN_SYNTHETIC_TABLE"
   },
   "outputs": [],
   "source": [
    "SELECT COUNT(*) FROM <DESTINATION_DATABASE>.<DESTINATION_SCHEMA>.<DESTINATION_SYNTHETIC_DATA_TABLE_NAME>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01908531-bc6f-482a-8e39-6bf1e368f6dc",
   "metadata": {
    "language": "sql",
    "name": "SAMPLE_SYNTHETIC_DATA"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM <DESTINATION_DATABASE>.<DESTINATION_SCHEMA>.<DESTINATION_SYNTHETIC_DATA_TABLE_NAME> LIMIT 4;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "lastEditStatus": {
   "authorEmail": "appan@rockfish.ai",
   "authorId": "5485715105355",
   "authorName": "APPANNORMALUSER",
   "lastEditTime": 1743538507103,
   "notebookId": "obomf55k2g5jafdamrws",
   "sessionId": "2d4ba883-be4c-4ba5-97d2-b465e4981bc8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
