{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgVdjEBIGUub"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U 'rockfish[labs]' -f 'https://docs142.rockfish.ai/packages/index.html'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lplEGc_Syjdf"
      },
      "outputs": [],
      "source": [
        "import rockfish as rf\n",
        "import rockfish.actions as ra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please replace `YOUR_API_KEY` with the assigned API key string. Note that it should be without quotes.\n",
        "\n",
        "For example, if the assigned API Key is `abcd1234`, you can do the following\n",
        "```python\n",
        "%env ROCKFISH_API_KEY=abcd1234\n",
        "conn = rf.Connection.from_env()\n",
        "```\n",
        "If you do not have API Key, please reach out to support@rockfish.ai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfprA7dZyjaw"
      },
      "outputs": [],
      "source": [
        "%env ROCKFISH_API_KEY=YOUR_API_KEY\n",
        "conn = rf.Connection.from_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22x8RaE4yjYS"
      },
      "outputs": [],
      "source": [
        "# download our example of timeseries data: pcap.csv\n",
        "!wget --no-clobber https://docs142.rockfish.ai/tutorials/pcap.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLqODOndyjVo"
      },
      "outputs": [],
      "source": [
        "dataset = rf.Dataset.from_csv(\"DC pcap\", \"pcap.csv\")\n",
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PDk-ealyjTK"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"encoder\": {\n",
        "        \"timestamp\": {\"field\": \"timestamp\"},\n",
        "        \"metadata\": [\n",
        "            {\"field\": \"srcip\", \"type\": \"categorical\"},\n",
        "            {\"field\": \"dstip\", \"type\": \"categorical\"},\n",
        "            {\"field\": \"srcport\", \"type\": \"categorical\"},\n",
        "            {\"field\": \"dstport\", \"type\": \"categorical\"},\n",
        "            {\"field\": \"proto\", \"type\": \"categorical\"},\n",
        "        ],\n",
        "        \"measurements\": [{\"field\": \"pkt_len\", \"type\": \"continuous\"}],\n",
        "    },\n",
        "    \"rtf\": {\n",
        "        \"mode\": \"relational\",\n",
        "        \"num_bootstrap\": 2,\n",
        "        \"parent\": {\n",
        "            \"epochs\": 1,\n",
        "            \"transformer\": {\"gpt2_config\": {\"layer\": 1, \"head\": 1, \"embed\": 1}},\n",
        "        },\n",
        "        \"child\": {\"output_max_length\": 2048, \"epochs\": 1},\n",
        "    },\n",
        "}\n",
        "# create train action\n",
        "train = ra.TrainTransformer(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2_N4q1ny6TD"
      },
      "outputs": [],
      "source": [
        "builder = rf.WorkflowBuilder()\n",
        "builder.add_dataset(dataset)\n",
        "builder.add_action(train, parents=[dataset])\n",
        "workflow = await builder.start(conn)\n",
        "print(f\"Workflow: {workflow.id()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSNt3HEfy6Qa"
      },
      "outputs": [],
      "source": [
        "async for log in workflow.logs():\n",
        "    print(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dutE6-cLy6OF"
      },
      "outputs": [],
      "source": [
        "model = await workflow.models().last()\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DstBC0O2BNdu"
      },
      "source": [
        "### Update the generated sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yho35SS-BNH-"
      },
      "outputs": [],
      "source": [
        "config[\"rtf\"].update({\"sessions\": 200})\n",
        "generate = ra.GenerateTransformer(config)\n",
        "save = ra.DatasetSave({\"name\": \"SyntheticData_large\"})\n",
        "builder = rf.WorkflowBuilder()\n",
        "builder.add_model(model)\n",
        "builder.add_action(generate, parents=[model])\n",
        "builder.add_action(save, parents=[generate])\n",
        "workflow = await builder.start(conn)\n",
        "print(f\"Workflow: {workflow.id()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur3ljMaKBQAA"
      },
      "outputs": [],
      "source": [
        "async for log in workflow.logs():\n",
        "    print(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJG8yLFFBP43"
      },
      "outputs": [],
      "source": [
        "syn = None\n",
        "async for sds in workflow.datasets():\n",
        "    syn = await sds.to_local(conn)\n",
        "syn.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate large dataset\n",
        "We recommend you to use our `SessionTarget` and please refer [here](https://docs142.rockfish.ai/data-gen.html#time-series-data) for details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''If wanting to concat by `concat_session_key`, \n",
        "update the config to include the sessions_key\n",
        "'''\n",
        "config[\"rtf\"].update({\"sessions_flag\": True})\n",
        "generate = ra.GenerateTransformer(config)\n",
        "\n",
        "session_target = ra.SessionTarget(target=1000)  # providing the target \"sessions\" value\n",
        "save = ra.DatasetSave(\n",
        "    name=\"target_synthetic\", concat_tables=True, concat_session_key=\"session_key\"\n",
        ")\n",
        "builder = rf.WorkflowBuilder()\n",
        "builder.add_model(model)\n",
        "builder.add_action(generate, parents=[model, session_target])\n",
        "builder.add_action(session_target, parents=[generate])\n",
        "builder.add_action(save, parents=[generate])\n",
        "workflow = await builder.start(conn)\n",
        "print(f\"Workflow: {workflow.id()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async for log in workflow.logs():\n",
        "    print(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "syn_large = None\n",
        "async for sds in workflow.datasets():\n",
        "    syn_large = await sds.to_local(conn)\n",
        "syn_large.to_pandas()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
