{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgJzHzDhcuJI"
   },
   "source": [
    "In this tutorial, we will guide you through the process of setting up an end-to-end continuously running workflow for the purposes of continuous ingestion of data.\n",
    "\n",
    "We will cover the following:\n",
    "\n",
    "- Preparing your dataset for synthetic data generation.\n",
    "- Utilizing Rockfish Recommendation Engine to automatically determine the most suitable model for training, along with key configurations and settings required for successful onboarding.\n",
    "- Generating and then evaluating synthetic data using the Rockfish Synthetic Data Assessor, which will help you improve the quality of your synthetic datasets.\n",
    "- Setting up an always on workflow using the settings generated from the onboarding process.\n",
    "- Applying custom labels to the models that are trained by the workflow.\n",
    "- Searching for a previously trained model in Rockfish's model store.\n",
    "- Using the model to generate synthetic data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72cj67zLabYj"
   },
   "source": [
    "### Install and Import Rockfish SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:24.266739Z",
     "start_time": "2024-12-13T18:28:23.841884Z"
    },
    "id": "GUWjYJW7Vspw"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U 'rockfish[labs]' -f 'https://packages.rockfish.ai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:25.711704Z",
     "start_time": "2024-12-13T18:28:24.270451Z"
    },
    "id": "I77DF8bPVx8j"
   },
   "outputs": [],
   "source": [
    "import rockfish as rf\n",
    "import rockfish.actions as ra\n",
    "from rockfish.labs.dataset_properties import (\n",
    "    DatasetPropertyExtractor,\n",
    "    FieldType,\n",
    "    EncoderType,\n",
    ")\n",
    "from rockfish.labs.steps import Recommender\n",
    "from rockfish.labs.metrics import marginal_dist_score\n",
    "from rockfish.labs.sda import SDA\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBGLOAALaZRt"
   },
   "source": [
    "### Connect to the Rockfish Platform\n",
    "\n",
    "❗❗ Replace API_KEY and API_URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:25.767099Z",
     "start_time": "2024-12-13T18:28:25.759966Z"
    },
    "id": "_r56lqHPZfBT"
   },
   "outputs": [],
   "source": [
    "api_key = \"API_KEY\"\n",
    "\n",
    "conn = rf.Connection.remote(\"https://api.rockfish.ai\", api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Onboard the dataset onto Rockfish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fg-fmB4apMI"
   },
   "source": [
    "### Load the Dataset\n",
    "\n",
    "We support ingesting other data formats, refer documentation for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:26.142076Z",
     "start_time": "2024-12-13T18:28:25.771181Z"
    },
    "id": "3foo29nQaf6U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738890154.026454 19731987 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-1.csv\n",
    "dataset = rf.Dataset.from_csv(\"finance\", \"finance-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:26.164463Z",
     "start_time": "2024-12-13T18:28:26.149617Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "wa2qr_ZIfDrL",
    "outputId": "be8c88d2-de90-42f7-89b3-a673e0f7eb16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>fraud</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>35.13</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 00:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>27.63</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 08:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>13.46</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 16:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>28.86</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-02 00:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M151143676</td>\n",
       "      <td>barsandrestaurants</td>\n",
       "      <td>64.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-02 08:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8774</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>62.58</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-09 15:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-09 23:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>18.85</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-10 07:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>41.86</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-10 15:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>65.76</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-10 23:53:05.114045618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8779 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer age gender    merchant            category  amount  fraud  \\\n",
       "0      C100045114   4      M  M348934600      transportation   35.13      0   \n",
       "1      C100045114   4      M  M348934600      transportation   27.63      0   \n",
       "2      C100045114   4      M  M348934600      transportation   13.46      0   \n",
       "3      C100045114   4      M  M348934600      transportation   28.86      0   \n",
       "4      C100045114   4      M  M151143676  barsandrestaurants   64.99      0   \n",
       "...           ...  ..    ...         ...                 ...     ...    ...   \n",
       "8774  C1335108214   3      M  M348934600      transportation   62.58      0   \n",
       "8775  C1335108214   3      M  M348934600      transportation   11.99      0   \n",
       "8776  C1335108214   3      M  M348934600      transportation   18.85      0   \n",
       "8777  C1335108214   3      M  M348934600      transportation   41.86      0   \n",
       "8778  C1335108214   3      M  M348934600      transportation   65.76      0   \n",
       "\n",
       "                         timestamp  \n",
       "0    2023-01-01 00:00:00.000000000  \n",
       "1    2023-01-01 08:00:00.000000000  \n",
       "2    2023-01-01 16:00:00.000000000  \n",
       "3    2023-01-02 00:00:00.000000000  \n",
       "4    2023-01-02 08:00:00.000000000  \n",
       "...                            ...  \n",
       "8774 2023-01-09 15:53:05.114045618  \n",
       "8775 2023-01-09 23:53:05.114045618  \n",
       "8776 2023-01-10 07:53:05.114045618  \n",
       "8777 2023-01-10 15:53:05.114045618  \n",
       "8778 2023-01-10 23:53:05.114045618  \n",
       "\n",
       "[8779 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd4qldYKbRo_"
   },
   "source": [
    "### Onboard the dataset onto Rockfish\n",
    "\n",
    "The onboarding workflow is a good starting point to get to a synthetic version of your dataset quickly.\n",
    "\n",
    "To ensure optimal synthetic data generation, it's crucial to provide domain-specific information related to your dataset. This helps Rockfish’s Recommendation Engine tailor the workflow to your specific needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:26.205670Z",
     "start_time": "2024-12-13T18:28:26.187105Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuvZsn7tbbI0",
    "outputId": "133f5554-15ca-4c29-dcc4-6938cb6ac00e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# _________________________________________________________________________\n",
      "#\n",
      "# RECOMMENDED CONFIGURATIONS\n",
      "#\n",
      "# (Remove or change any actions or configurations that are inappropriate\n",
      "#  for your use case, or add missing ones)\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n",
      "We detected a timeseries dataset with the following properties:\n",
      "Dimensions of dataset: (8779 x 8)\n",
      "Metadata fields: ['age', 'gender']\n",
      "Measurement fields: ['merchant', 'category', 'amount', 'fraud']\n",
      "Timestamp field: timestamp\n",
      "Session key field: customer\n",
      "Number of sessions: 658\n",
      "\n",
      "# _________________________________________________________________________\n",
      "#\n",
      "# ~~~~~ Pre-processing recommendations ~~~~~\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "# _________________________________________________________________________\n",
      "#\n",
      "# ~~~~~ Model recommendations ~~~~~\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n",
      "We recommend using the TimeGAN model.\n",
      "\n",
      "For training, we recommend the following model parameters:\n",
      "DGConfig(sample_len=1, activate_normalization_per_sample=True, generator_attribute_num_layers=5, generator_feature_num_layers=1, epoch=10, batch_size=16, g_lr=0.0001, d_lr=0.0001, attr_d_beta1=0.5, sessions=200, extras={})\n",
      "\n",
      "For generation, we recommend the following model parameters:\n",
      "sessions: 200\n",
      "\n",
      "# _________________________________________________________________________\n",
      "#\n",
      "# ~~~~~ Post-processing recommendations ~~~~~\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_properties = DatasetPropertyExtractor(\n",
    "    dataset,\n",
    "    session_key=\"customer\",\n",
    "    metadata_fields=[\"age\", \"gender\"],\n",
    ").extract()\n",
    "recommender_output = Recommender(dataset_properties).run()\n",
    "print(recommender_output.report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQQOTUnxb6XJ"
   },
   "source": [
    "#### Run the recommended workflow to get a synthetic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:26.709004Z",
     "start_time": "2024-12-13T18:28:26.226273Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4mY164eb9Ic",
    "outputId": "f7bcd58f-1d0c-4862-848c-169bee00b49a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow: 2EryeAqlG2x2PHFOol5q5f\n"
     ]
    }
   ],
   "source": [
    "rec_actions = recommender_output.actions\n",
    "save = ra.DatasetSave(name=\"synthetic\")\n",
    "\n",
    "# use recommended actions in a Rockfish workflow\n",
    "builder = rf.WorkflowBuilder()\n",
    "builder.add_path(dataset, *rec_actions, save)\n",
    "\n",
    "# run the Rockfish workflow\n",
    "pre_workflow = await builder.start(conn)\n",
    "print(f\"Workflow: {pre_workflow.id()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6bScF8ncLN4"
   },
   "source": [
    "View logs for the running workflow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:41.926198Z",
     "start_time": "2024-12-13T18:28:26.712917Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TeT2DFZcKj2",
    "outputId": "2c8df097-0640-4e90-caec-1c13fe77f36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-07T01:02:35Z dataset-load: INFO Loading dataset '5yz5eoxezE3DpVcJbLr0pb' with 8779 rows\n",
      "2025-02-07T01:02:35Z train-time-gan: WARN Unsafe time cast on timestamp\n",
      "2025-02-07T01:02:36Z train-time-gan: INFO Starting DG training job\n",
      "2025-02-07T01:02:43Z train-time-gan: INFO Epoch 1 completed.\n",
      "2025-02-07T01:02:49Z train-time-gan: INFO Epoch 2 completed.\n",
      "2025-02-07T01:02:56Z train-time-gan: INFO Epoch 3 completed.\n",
      "2025-02-07T01:03:02Z train-time-gan: INFO Epoch 4 completed.\n",
      "2025-02-07T01:03:09Z train-time-gan: INFO Epoch 5 completed.\n",
      "2025-02-07T01:03:16Z train-time-gan: INFO Epoch 6 completed.\n",
      "2025-02-07T01:03:22Z train-time-gan: INFO Epoch 7 completed.\n",
      "2025-02-07T01:03:28Z train-time-gan: INFO Epoch 8 completed.\n",
      "2025-02-07T01:03:34Z train-time-gan: INFO Epoch 9 completed.\n",
      "2025-02-07T01:03:40Z train-time-gan: INFO Epoch 10 completed.\n",
      "2025-02-07T01:03:42Z train-time-gan: INFO Training completed. Uploaded model 5f1d0c7d-e4ef-11ef-8b30-b6c89c2b7480\n",
      "2025-02-07T01:03:42Z generate-time-gan: INFO Downloading model with model_id='5f1d0c7d-e4ef-11ef-8b30-b6c89c2b7480'...\n",
      "2025-02-07T01:03:43Z generate-time-gan: INFO Generating 200 sessions...\n",
      "2025-02-07T01:03:44Z dataset-save: INFO using field 'session_key' to concatenate tables\n",
      "2025-02-07T01:03:44Z dataset-save: INFO Saved dataset '6cLweCCiaBmrkVU5FKiUWw' with 3524 rows\n"
     ]
    }
   ],
   "source": [
    "async for log in pre_workflow.logs():\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEDizQAScg8J"
   },
   "source": [
    "Download and view the synthetic dataset locally:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:42.825909Z",
     "start_time": "2024-12-13T18:29:41.945275Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "G4_0TVMncghE",
    "outputId": "5ac69b4c-d4db-46f8-9f6b-63264954afc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>fraud</th>\n",
       "      <th>session_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05 15:14:19.306</td>\n",
       "      <td>16.613481</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M85975013</td>\n",
       "      <td>home</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-05 23:53:21.843</td>\n",
       "      <td>33.693912</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>otherservices</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-06 05:47:57.156</td>\n",
       "      <td>30.031166</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06 11:56:29.138</td>\n",
       "      <td>26.455817</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06 18:44:22.751</td>\n",
       "      <td>22.902034</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>2023-01-06 19:29:35.328</td>\n",
       "      <td>1512.302483</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M1823072687</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>2023-01-07 03:43:06.071</td>\n",
       "      <td>1402.310192</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M1823072687</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>2023-01-07 11:21:29.069</td>\n",
       "      <td>1294.213933</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M1823072687</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>2023-01-07 18:16:48.542</td>\n",
       "      <td>1157.108533</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M1823072687</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>2023-01-08 00:26:14.226</td>\n",
       "      <td>1002.081864</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M1823072687</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3524 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp       amount age gender     merchant  \\\n",
       "0    2023-01-05 15:14:19.306    16.613481   4      M    M85975013   \n",
       "1    2023-01-05 23:53:21.843    33.693912   U      M   M348934600   \n",
       "2    2023-01-06 05:47:57.156    30.031166   U      M   M348934600   \n",
       "3    2023-01-06 11:56:29.138    26.455817   U      M   M348934600   \n",
       "4    2023-01-06 18:44:22.751    22.902034   U      M   M348934600   \n",
       "...                      ...          ...  ..    ...          ...   \n",
       "3519 2023-01-06 19:29:35.328  1512.302483   3      M  M1823072687   \n",
       "3520 2023-01-07 03:43:06.071  1402.310192   3      M  M1823072687   \n",
       "3521 2023-01-07 11:21:29.069  1294.213933   3      M  M1823072687   \n",
       "3522 2023-01-07 18:16:48.542  1157.108533   3      M  M1823072687   \n",
       "3523 2023-01-08 00:26:14.226  1002.081864   3      M  M1823072687   \n",
       "\n",
       "            category  fraud  session_key  \n",
       "0               home      0          0.0  \n",
       "1      otherservices      0          1.0  \n",
       "2     transportation      0          1.0  \n",
       "3     transportation      0          1.0  \n",
       "4     transportation      0          1.0  \n",
       "...              ...    ...          ...  \n",
       "3519  transportation      0        199.0  \n",
       "3520  transportation      0        199.0  \n",
       "3521  transportation      0        199.0  \n",
       "3522  transportation      0        199.0  \n",
       "3523  transportation      0        199.0  \n",
       "\n",
       "[3524 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn = await pre_workflow.datasets().last()\n",
    "syn = await syn.to_local(conn)\n",
    "syn.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmhdoeldtI00"
   },
   "source": [
    "### Evaluate the synthetic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:42.855843Z",
     "start_time": "2024-12-13T18:29:42.853264Z"
    },
    "cellView": "form",
    "id": "vmngYsA7cTBo"
   },
   "outputs": [],
   "source": [
    "# @title ##### Define a helper function `get_fidelity_score()` to calculate the marginal distribution score:\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "def get_fidelity_score(source, source_dataset_properties, syn):\n",
    "    source = copy.deepcopy(source)\n",
    "    syn = copy.deepcopy(syn)\n",
    "\n",
    "    columns_to_drop = [source_dataset_properties.session_key]\n",
    "    source.table = source.table.drop_columns(columns_to_drop)\n",
    "\n",
    "    columns_to_drop = [\"session_key\"]\n",
    "    syn.table = syn.table.drop_columns(columns_to_drop)\n",
    "\n",
    "    categorical_measurements = source_dataset_properties.filter_fields(\n",
    "        ftype=FieldType.MEASUREMENT, etype=EncoderType.CATEGORICAL\n",
    "    )\n",
    "\n",
    "    return marginal_dist_score(\n",
    "        source,\n",
    "        syn,\n",
    "        metadata=source_dataset_properties.metadata_fields,\n",
    "        other_categorical=categorical_measurements,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:42.913522Z",
     "start_time": "2024-12-13T18:29:42.879236Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNMp4sEeq2oT",
    "outputId": "6e2a69f5-5104-4692-c4ab-e02d6f08a114"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7292203197330803"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fidelity_score(\n",
    "    source=dataset, source_dataset_properties=dataset_properties, syn=syn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the actions look good, we can use them for setting up the always-on workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:42.933619Z",
     "start_time": "2024-12-13T18:29:42.931552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rockfish.actions.dg.TrainTimeGAN at 0x1767987d0>,\n",
       " <rockfish.actions.dg.GenerateTimeGAN at 0x1771bca40>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:42.952790Z",
     "start_time": "2024-12-13T18:29:42.951176Z"
    }
   },
   "outputs": [],
   "source": [
    "train_actions = rec_actions[:-1]\n",
    "generate_actions = rec_actions[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set up an always-on workflow for continuous data ingestion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employ the DataStreamLoad action to keep the workflow always on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:43.030173Z",
     "start_time": "2024-12-13T18:29:42.957215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion Workflow ID: 1HD4Hj5x8lBvoPgUSCTalW\n"
     ]
    }
   ],
   "source": [
    "# reduce the batch size for the following ingested data stream as the batch\n",
    "# size should be smaller than the number of sessions in the dataset\n",
    "train_actions[0].config().doppelganger.batch_size = 14\n",
    "stream = ra.DatastreamLoad()\n",
    "\n",
    "builder = rf.WorkflowBuilder()\n",
    "builder.add(stream, alias=\"input\")\n",
    "builder.add_path(*train_actions, parents=[\"input\"], alias=\"train_actions\")\n",
    "ingest_workflow = await builder.start(conn)\n",
    "print(f\"Ingestion Workflow ID: {ingest_workflow.id()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the data files to the workflow stream\n",
    "\n",
    "- each input is a dataset\n",
    "- each output is a trained model stored to the model_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data files to the workflow stream\n",
    "\n",
    "Replace the workflow ID with the actual workflow ID of the workflow that was set up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the sample files for the datastream workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:44.319515Z",
     "start_time": "2024-12-13T18:29:43.040553Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738890225.401350 19731987 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1738890225.667719 19731987 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1738890225.901019 19731987 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-2.csv\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-3.csv\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the workflow ID with the ID of the workflow that was just set up.\n",
    "\n",
    "This also allows you to run the data-ingestion service in an independent process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:44.394565Z",
     "start_time": "2024-12-13T18:29:44.332382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the workflow with the previous ID without need to re-build the workflow\n",
    "workflow_id = ingest_workflow.id()  # insert workflow ID here\n",
    "workflow = await conn.get_workflow(workflow_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:30:16.784761Z",
     "start_time": "2024-12-13T18:29:44.405420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing finance-2 to datastream...\n",
      "Writing finance-3 to datastream...\n",
      "Writing finance-4 to datastream...\n"
     ]
    }
   ],
   "source": [
    "for file_num in range(2, 5):\n",
    "    data = rf.Dataset.from_csv(\"finance\", f\"finance-{file_num}.csv\")\n",
    "    await workflow.write_datastream(\n",
    "        \"input\", data\n",
    "    )  # \"input\" is the pre-set alias of the datastream\n",
    "    print(f\"Writing finance-{file_num} to datastream...\")\n",
    "    time.sleep(10)\n",
    "await workflow.close_datastream(\n",
    "    \"input\"\n",
    ")  # \"input\" is the pre-set alias of the datastream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:30:35.957341Z",
     "start_time": "2024-12-13T18:30:16.797330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-07T01:03:47Z train_actions: WARN Unsafe time cast on timestamp\n",
      "2025-02-07T01:03:48Z train_actions: INFO Starting DG training job\n",
      "2025-02-07T01:03:57Z train_actions: INFO Epoch 1 completed.\n",
      "2025-02-07T01:04:06Z train_actions: INFO Epoch 2 completed.\n",
      "2025-02-07T01:04:16Z train_actions: INFO Epoch 3 completed.\n",
      "2025-02-07T01:03:47Z input: INFO Read batch with 8850 rows from datastream\n",
      "2025-02-07T01:03:58Z input: INFO Read batch with 9080 rows from datastream\n",
      "2025-02-07T01:04:08Z input: INFO Read batch with 6979 rows from datastream\n",
      "2025-02-07T01:04:25Z train_actions: INFO Epoch 4 completed.\n",
      "2025-02-07T01:04:36Z train_actions: INFO Epoch 5 completed.\n",
      "2025-02-07T01:04:45Z train_actions: INFO Epoch 6 completed.\n",
      "2025-02-07T01:04:55Z train_actions: INFO Epoch 7 completed.\n",
      "2025-02-07T01:05:04Z train_actions: INFO Epoch 8 completed.\n",
      "2025-02-07T01:05:13Z train_actions: INFO Epoch 9 completed.\n",
      "2025-02-07T01:05:21Z train_actions: INFO Epoch 10 completed.\n",
      "2025-02-07T01:05:22Z train_actions: INFO Training completed. Uploaded model 9b3b13e0-e4ef-11ef-8b30-b6c89c2b7480\n",
      "2025-02-07T01:05:23Z train_actions: WARN Unsafe time cast on timestamp\n",
      "2025-02-07T01:05:23Z train_actions: INFO Starting DG training job\n",
      "2025-02-07T01:05:32Z train_actions: INFO Epoch 1 completed.\n",
      "2025-02-07T01:05:41Z train_actions: INFO Epoch 2 completed.\n",
      "2025-02-07T01:05:48Z train_actions: INFO Epoch 3 completed.\n",
      "2025-02-07T01:05:56Z train_actions: INFO Epoch 4 completed.\n",
      "2025-02-07T01:06:04Z train_actions: INFO Epoch 5 completed.\n",
      "2025-02-07T01:06:13Z train_actions: INFO Epoch 6 completed.\n",
      "2025-02-07T01:06:21Z train_actions: INFO Epoch 7 completed.\n",
      "2025-02-07T01:06:30Z train_actions: INFO Epoch 8 completed.\n",
      "2025-02-07T01:06:38Z train_actions: INFO Epoch 9 completed.\n",
      "2025-02-07T01:06:47Z train_actions: INFO Epoch 10 completed.\n",
      "2025-02-07T01:06:49Z train_actions: INFO Training completed. Uploaded model ced963ac-e4ef-11ef-a813-fafbc229dfe9\n",
      "2025-02-07T01:06:49Z train_actions: WARN Unsafe time cast on timestamp\n",
      "2025-02-07T01:06:50Z train_actions: INFO Starting DG training job\n",
      "2025-02-07T01:06:57Z train_actions: INFO Epoch 1 completed.\n",
      "2025-02-07T01:07:04Z train_actions: INFO Epoch 2 completed.\n",
      "2025-02-07T01:07:11Z train_actions: INFO Epoch 3 completed.\n",
      "2025-02-07T01:07:18Z train_actions: INFO Epoch 4 completed.\n",
      "2025-02-07T01:07:24Z train_actions: INFO Epoch 5 completed.\n",
      "2025-02-07T01:07:31Z train_actions: INFO Epoch 6 completed.\n",
      "2025-02-07T01:07:38Z train_actions: INFO Epoch 7 completed.\n",
      "2025-02-07T01:07:45Z train_actions: INFO Epoch 8 completed.\n",
      "2025-02-07T01:07:52Z train_actions: INFO Epoch 9 completed.\n",
      "2025-02-07T01:07:59Z train_actions: INFO Epoch 10 completed.\n",
      "2025-02-07T01:08:00Z train_actions: INFO Training completed. Uploaded model f9756bb9-e4ef-11ef-8b30-b6c89c2b7480\n"
     ]
    }
   ],
   "source": [
    "# check the status of the workflow\n",
    "async for log in workflow.logs():\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Add custom labels to the models that are generated\n",
    "\n",
    "These labels can be used later to filter models based off custom parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:30:36.101597Z",
     "start_time": "2024-12-13T18:30:35.967727Z"
    }
   },
   "outputs": [],
   "source": [
    "usage = [\"experimental\", \"staging\", \"production\"]\n",
    "i = 0\n",
    "async for model in conn.list_models(labels={\"workflow_id\": workflow_id}):\n",
    "    await model.add_labels(conn, usage=usage[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate synthetic data using the trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide query params to the model_store search to get appropriate models as response\n",
    "\n",
    "This can be used if the models trained were previously tagged, the default label that exists is 'workflow_id' which is the id of the workflow that trained the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:30:36.180287Z",
     "start_time": "2024-12-13T18:30:36.106879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='f9756bb9-e4ef-11ef-8b30-b6c89c2b7480', labels={'usage': 'production', 'workflow_id': '1HD4Hj5x8lBvoPgUSCTalW'}, create_time=datetime.datetime(2025, 2, 7, 1, 8, tzinfo=datetime.timezone.utc), size_bytes=16009216)\n"
     ]
    }
   ],
   "source": [
    "async for model in conn.list_models(labels={\"usage\": \"production\"}):\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model from the list of queried models and fetch it from remote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:30:36.330208Z",
     "start_time": "2024-12-13T18:30:36.185898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='f9756bb9-e4ef-11ef-8b30-b6c89c2b7480', labels={'usage': 'production', 'workflow_id': '1HD4Hj5x8lBvoPgUSCTalW'}, create_time=datetime.datetime(2025, 2, 7, 1, 8, tzinfo=datetime.timezone.utc), size_bytes=16009216)\n"
     ]
    }
   ],
   "source": [
    "model = await rf.Model.from_id(\n",
    "    conn,\n",
    "    model.id,  # insert model id here of the filtered model after querying\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide the model and the synthesis config to a workflow to generate a synthetic dataset as the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow ID: 5rjOlzD7ZzFg3PHSluBqkk\n"
     ]
    }
   ],
   "source": [
    "builder = rf.WorkflowBuilder()\n",
    "builder.add(model)\n",
    "builder.add(*generate_actions, parents=[model], alias=\"gen\")\n",
    "builder.add(ra.DatasetSave(name=\"syn_data\"), parents=[\"gen\"])\n",
    "workflow = await builder.start(conn)\n",
    "print(f\"Workflow ID: {workflow.id()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-07T01:08:02Z gen: INFO Downloading model with model_id='f9756bb9-e4ef-11ef-8b30-b6c89c2b7480'...\n",
      "2025-02-07T01:08:02Z gen: INFO Generating 200 sessions...\n",
      "2025-02-07T01:08:03Z dataset-save: INFO using field 'session_key' to concatenate tables\n",
      "2025-02-07T01:08:03Z dataset-save: INFO Saved dataset '5EK43L3e7lZkt5RvMHkfSI' with 3436 rows\n"
     ]
    }
   ],
   "source": [
    "async for log in workflow.logs():\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>fraud</th>\n",
       "      <th>session_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-16 10:29:30.608</td>\n",
       "      <td>5769.000968</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>otherservices</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-16 19:42:28.983</td>\n",
       "      <td>5639.624898</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-17 06:36:53.880</td>\n",
       "      <td>5116.755126</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-17 19:10:35.828</td>\n",
       "      <td>4433.340920</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-18 08:47:56.532</td>\n",
       "      <td>3812.356856</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>2023-01-26 17:32:19.900</td>\n",
       "      <td>3096.980100</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>2023-01-27 06:28:56.743</td>\n",
       "      <td>3049.270808</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>2023-01-27 19:22:46.724</td>\n",
       "      <td>3031.661770</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>2023-01-28 08:12:34.148</td>\n",
       "      <td>3010.777257</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>2023-01-28 21:01:06.030</td>\n",
       "      <td>2992.999674</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3436 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp       amount age gender    merchant  \\\n",
       "0    2023-01-16 10:29:30.608  5769.000968   2      M  M348934600   \n",
       "1    2023-01-16 19:42:28.983  5639.624898   2      M  M348934600   \n",
       "2    2023-01-17 06:36:53.880  5116.755126   2      M  M348934600   \n",
       "3    2023-01-17 19:10:35.828  4433.340920   2      M  M348934600   \n",
       "4    2023-01-18 08:47:56.532  3812.356856   2      M  M348934600   \n",
       "...                      ...          ...  ..    ...         ...   \n",
       "3431 2023-01-26 17:32:19.900  3096.980100   2      M  M348934600   \n",
       "3432 2023-01-27 06:28:56.743  3049.270808   2      M  M348934600   \n",
       "3433 2023-01-27 19:22:46.724  3031.661770   2      M  M348934600   \n",
       "3434 2023-01-28 08:12:34.148  3010.777257   2      M  M348934600   \n",
       "3435 2023-01-28 21:01:06.030  2992.999674   2      M  M348934600   \n",
       "\n",
       "            category  fraud  session_key  \n",
       "0      otherservices      0          0.0  \n",
       "1     transportation      0          0.0  \n",
       "2     transportation      0          0.0  \n",
       "3     transportation      0          0.0  \n",
       "4     transportation      0          0.0  \n",
       "...              ...    ...          ...  \n",
       "3431  transportation      0        199.0  \n",
       "3432  transportation      0        199.0  \n",
       "3433  transportation      0        199.0  \n",
       "3434  transportation      0        199.0  \n",
       "3435  transportation      0        199.0  \n",
       "\n",
       "[3436 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_data = await workflow.datasets().concat(conn)\n",
    "syn_data.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
