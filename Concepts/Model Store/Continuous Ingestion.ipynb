{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgJzHzDhcuJI"
   },
   "source": [
    "In this tutorial, we will guide you through the process of setting up an end-to-end continuously running workflow for the purposes of continuous ingestion of data.\n",
    "\n",
    "We will cover the following:\n",
    "\n",
    "- Preparing your dataset for synthetic data generation.\n",
    "- Utilizing Rockfish Recommendation Engine to automatically determine the most suitable model for training, along with key configurations and settings required for successful onboarding.\n",
    "- Generating and then evaluating synthetic data using the Rockfish Synthetic Data Assessor, which will help you improve the quality of your synthetic datasets.\n",
    "- Setting up an always on workflow using the settings generated from the onboarding process.\n",
    "- Applying custom labels to the models that are trained by the workflow.\n",
    "- Searching for a previously trained model in Rockfish's model store.\n",
    "- Using the model to generate synthetic data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72cj67zLabYj"
   },
   "source": [
    "### Install and Import Rockfish SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GUWjYJW7Vspw",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:24.266739Z",
     "start_time": "2024-12-13T18:28:23.841884Z"
    }
   },
   "source": [
    "%%capture\n",
    "%pip install -U 'rockfish[labs]' -f 'https://packages.rockfish.ai'"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I77DF8bPVx8j",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:25.711704Z",
     "start_time": "2024-12-13T18:28:24.270451Z"
    }
   },
   "source": [
    "import rockfish as rf\n",
    "import rockfish.actions as ra\n",
    "from rockfish.labs.dataset_properties import (\n",
    "    DatasetPropertyExtractor,\n",
    "    FieldType,\n",
    "    EncoderType,\n",
    ")\n",
    "from rockfish.labs.steps import Recommender\n",
    "from rockfish.labs.metrics import marginal_dist_score\n",
    "from rockfish.labs.sda import SDA\n",
    "\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBGLOAALaZRt"
   },
   "source": [
    "### Connect to the Rockfish Platform\n",
    "\n",
    "❗❗ Replace API_KEY and API_URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_r56lqHPZfBT",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:25.767099Z",
     "start_time": "2024-12-13T18:28:25.759966Z"
    }
   },
   "source": [
    "api_key = \"API_KEY\"\n",
    "\n",
    "conn = rf.Connection.remote(\"https://api.rockfish.ai\", api_key)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Onboard the dataset onto Rockfish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fg-fmB4apMI"
   },
   "source": [
    "### Load the Dataset\n",
    "\n",
    "We support ingesting other data formats, refer documentation for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3foo29nQaf6U",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:26.142076Z",
     "start_time": "2024-12-13T18:28:25.771181Z"
    }
   },
   "source": [
    "%%capture\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-1.csv\n",
    "dataset = rf.Dataset.from_csv(\"finance\", \"finance-1.csv\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734114505.796440 3278498 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "wa2qr_ZIfDrL",
    "outputId": "be8c88d2-de90-42f7-89b3-a673e0f7eb16",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:26.164463Z",
     "start_time": "2024-12-13T18:28:26.149617Z"
    }
   },
   "source": [
    "dataset.to_pandas()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         customer age gender    merchant            category  amount  fraud  \\\n",
       "0      C100045114   4      M  M348934600      transportation   35.13      0   \n",
       "1      C100045114   4      M  M348934600      transportation   27.63      0   \n",
       "2      C100045114   4      M  M348934600      transportation   13.46      0   \n",
       "3      C100045114   4      M  M348934600      transportation   28.86      0   \n",
       "4      C100045114   4      M  M151143676  barsandrestaurants   64.99      0   \n",
       "...           ...  ..    ...         ...                 ...     ...    ...   \n",
       "8774  C1335108214   3      M  M348934600      transportation   62.58      0   \n",
       "8775  C1335108214   3      M  M348934600      transportation   11.99      0   \n",
       "8776  C1335108214   3      M  M348934600      transportation   18.85      0   \n",
       "8777  C1335108214   3      M  M348934600      transportation   41.86      0   \n",
       "8778  C1335108214   3      M  M348934600      transportation   65.76      0   \n",
       "\n",
       "                         timestamp  \n",
       "0    2023-01-01 00:00:00.000000000  \n",
       "1    2023-01-01 08:00:00.000000000  \n",
       "2    2023-01-01 16:00:00.000000000  \n",
       "3    2023-01-02 00:00:00.000000000  \n",
       "4    2023-01-02 08:00:00.000000000  \n",
       "...                            ...  \n",
       "8774 2023-01-09 15:53:05.114045618  \n",
       "8775 2023-01-09 23:53:05.114045618  \n",
       "8776 2023-01-10 07:53:05.114045618  \n",
       "8777 2023-01-10 15:53:05.114045618  \n",
       "8778 2023-01-10 23:53:05.114045618  \n",
       "\n",
       "[8779 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>fraud</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>35.13</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 00:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>27.63</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 08:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>13.46</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 16:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>28.86</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-02 00:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C100045114</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M151143676</td>\n",
       "      <td>barsandrestaurants</td>\n",
       "      <td>64.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-02 08:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8774</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>62.58</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-09 15:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-09 23:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>18.85</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-10 07:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>41.86</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-10 15:53:05.114045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778</th>\n",
       "      <td>C1335108214</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>65.76</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-10 23:53:05.114045618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8779 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd4qldYKbRo_"
   },
   "source": [
    "### Onboard the dataset onto Rockfish\n",
    "\n",
    "The onboarding workflow is a good starting point to get to a synthetic version of your dataset quickly.\n",
    "\n",
    "To ensure optimal synthetic data generation, it's crucial to provide domain-specific information related to your dataset. This helps Rockfish’s Recommendation Engine tailor the workflow to your specific needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuvZsn7tbbI0",
    "outputId": "133f5554-15ca-4c29-dcc4-6938cb6ac00e",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:26.205670Z",
     "start_time": "2024-12-13T18:28:26.187105Z"
    }
   },
   "source": [
    "dataset_properties = DatasetPropertyExtractor(\n",
    "    dataset,\n",
    "    session_key=\"customer\",\n",
    "    metadata_fields=[\"age\", \"gender\"],\n",
    ").extract()\n",
    "recommender_output = Recommender(dataset_properties).run()\n",
    "print(recommender_output.report)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# _________________________________________________________________________\n",
      "#\n",
      "# RECOMMENDED CONFIGURATIONS\n",
      "#\n",
      "# (Remove or change any actions or configurations that are inappropriate\n",
      "#  for your use case, or add missing ones)\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n",
      "We detected a timeseries dataset with the following properties:\n",
      "Dimensions of dataset: (8779 x 8)\n",
      "Metadata fields: ['age', 'gender']\n",
      "Measurement fields: ['category', 'amount', 'fraud', 'merchant']\n",
      "Timestamp field: timestamp\n",
      "Session key field: customer\n",
      "Number of sessions: 658\n",
      "\n",
      "# _________________________________________________________________________\n",
      "#\n",
      "# ~~~~~ Pre-processing recommendations ~~~~~\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "# _________________________________________________________________________\n",
      "#\n",
      "# ~~~~~ Model recommendations ~~~~~\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n",
      "We recommend using the TimeGAN model.\n",
      "\n",
      "For training, we recommend the following model parameters:\n",
      "DGConfig(sample_len=1, activate_normalization_per_sample=True, generator_attribute_num_layers=5, generator_feature_num_layers=1, epoch=10, epoch_checkpoint_freq=10, batch_size=16, g_lr=0.0001, d_lr=0.0001, attr_d_beta1=0.5, sessions=200, extras={})\n",
      "\n",
      "For generation, we recommend the following model parameters:\n",
      "sessions: 200\n",
      "\n",
      "# _________________________________________________________________________\n",
      "#\n",
      "# ~~~~~ Post-processing recommendations ~~~~~\n",
      "# _________________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQQOTUnxb6XJ"
   },
   "source": [
    "#### Run the recommended workflow to get a synthetic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4mY164eb9Ic",
    "outputId": "f7bcd58f-1d0c-4862-848c-169bee00b49a",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:28:26.709004Z",
     "start_time": "2024-12-13T18:28:26.226273Z"
    }
   },
   "source": [
    "rec_actions = recommender_output.actions\n",
    "save = ra.DatasetSave({\"name\": \"synthetic\"})\n",
    "\n",
    "# use recommended actions in a Rockfish workflow\n",
    "builder = rf.WorkflowBuilder()\n",
    "builder.add_path(dataset, *rec_actions, save)\n",
    "\n",
    "# run the Rockfish workflow\n",
    "pre_workflow = await builder.start(conn)\n",
    "print(f\"Workflow: {pre_workflow.id()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow: 24c5g5gUp8fBBuiEc6IXlu\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6bScF8ncLN4"
   },
   "source": [
    "View logs for the running workflow:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TeT2DFZcKj2",
    "outputId": "2c8df097-0640-4e90-caec-1c13fe77f36c",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:41.926198Z",
     "start_time": "2024-12-13T18:28:26.712917Z"
    }
   },
   "source": [
    "async for log in pre_workflow.logs():\n",
    "    print(log)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13T18:29:03Z dataset-load: INFO Loading dataset '3C7tO4yfBNV6F2yazRRMhW' with 8779 rows\n",
      "2024-12-13T18:28:53Z train-time-gan: WARN Unsafe time cast on timestamp\n",
      "2024-12-13T18:28:54Z train-time-gan: INFO Starting DG training job\n",
      "2024-12-13T18:29:01Z train-time-gan: INFO Epoch 1 completed.\n",
      "2024-12-13T18:29:08Z train-time-gan: INFO Epoch 2 completed.\n",
      "2024-12-13T18:29:15Z train-time-gan: INFO Epoch 3 completed.\n",
      "2024-12-13T18:29:22Z train-time-gan: INFO Epoch 4 completed.\n",
      "2024-12-13T18:29:28Z train-time-gan: INFO Epoch 5 completed.\n",
      "2024-12-13T18:29:35Z train-time-gan: INFO Epoch 6 completed.\n",
      "2024-12-13T18:29:42Z train-time-gan: INFO Epoch 7 completed.\n",
      "2024-12-13T18:29:49Z train-time-gan: INFO Epoch 8 completed.\n",
      "2024-12-13T18:29:55Z train-time-gan: INFO Epoch 9 completed.\n",
      "2024-12-13T18:30:02Z train-time-gan: INFO Epoch 10 completed.\n",
      "2024-12-13T18:30:04Z train-time-gan: INFO Training completed. Uploaded model 35a6179d-b980-11ef-8430-ba032c12226b\n",
      "2024-12-13T18:30:14Z generate-time-gan: INFO Downloading model with model_id='35a6179d-b980-11ef-8430-ba032c12226b'...\n",
      "2024-12-13T18:30:15Z generate-time-gan: INFO Generating 200 sessions...\n",
      "2024-12-13T18:29:40Z dataset-save: INFO using field 'session_key' to concatenate tables\n",
      "2024-12-13T18:29:40Z dataset-save: INFO Saved dataset '5L8GYanE1l8ZwgNXVXIhqj' with 3648 rows\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEDizQAScg8J"
   },
   "source": [
    "Download and view the synthetic dataset locally:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "G4_0TVMncghE",
    "outputId": "5ac69b4c-d4db-46f8-9f6b-63264954afc3",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:42.825909Z",
     "start_time": "2024-12-13T18:29:41.945275Z"
    }
   },
   "source": [
    "syn = await pre_workflow.datasets().last()\n",
    "syn = await syn.to_local(conn)\n",
    "syn.to_pandas()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   timestamp       amount age gender     merchant  \\\n",
       "0    2023-01-02 15:57:34.730   263.735295   2      F     M3697346   \n",
       "1    2023-01-05 05:48:52.187  5155.641451   2      F  M1842530320   \n",
       "2    2023-01-05 10:17:40.601  4734.079236   1      M  M1823072687   \n",
       "3    2023-01-05 21:27:22.327  4488.497978   1      M   M348934600   \n",
       "4    2023-01-06 10:27:13.000  4050.189258   1      M   M348934600   \n",
       "...                      ...          ...  ..    ...          ...   \n",
       "3643 2023-01-15 01:44:03.325  3621.789114   2      M   M348934600   \n",
       "3644 2023-01-15 11:17:00.871  3381.368415   2      M   M348934600   \n",
       "3645 2023-01-15 19:49:49.168  3202.180809   2      M   M348934600   \n",
       "3646 2023-01-16 03:16:15.912  3097.431585   2      M   M348934600   \n",
       "3647 2023-01-02 12:19:37.128   550.702234   3      M    M85975013   \n",
       "\n",
       "            category  fraud  session_key  \n",
       "0              hyper      1          0.0  \n",
       "1             health      1          1.0  \n",
       "2     transportation      0          2.0  \n",
       "3     transportation      0          2.0  \n",
       "4     transportation      0          2.0  \n",
       "...              ...    ...          ...  \n",
       "3643  transportation      0        198.0  \n",
       "3644  transportation      0        198.0  \n",
       "3645  transportation      0        198.0  \n",
       "3646  transportation      0        198.0  \n",
       "3647   otherservices      1        199.0  \n",
       "\n",
       "[3648 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>fraud</th>\n",
       "      <th>session_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02 15:57:34.730</td>\n",
       "      <td>263.735295</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>M3697346</td>\n",
       "      <td>hyper</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-05 05:48:52.187</td>\n",
       "      <td>5155.641451</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>M1842530320</td>\n",
       "      <td>health</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-05 10:17:40.601</td>\n",
       "      <td>4734.079236</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M1823072687</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05 21:27:22.327</td>\n",
       "      <td>4488.497978</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06 10:27:13.000</td>\n",
       "      <td>4050.189258</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>2023-01-15 01:44:03.325</td>\n",
       "      <td>3621.789114</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>2023-01-15 11:17:00.871</td>\n",
       "      <td>3381.368415</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>2023-01-15 19:49:49.168</td>\n",
       "      <td>3202.180809</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>2023-01-16 03:16:15.912</td>\n",
       "      <td>3097.431585</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>M348934600</td>\n",
       "      <td>transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>2023-01-02 12:19:37.128</td>\n",
       "      <td>550.702234</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>M85975013</td>\n",
       "      <td>otherservices</td>\n",
       "      <td>1</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3648 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmhdoeldtI00"
   },
   "source": [
    "### Evaluate the synthetic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "vmngYsA7cTBo",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:42.855843Z",
     "start_time": "2024-12-13T18:29:42.853264Z"
    }
   },
   "source": [
    "# @title ##### Define a helper function `get_fidelity_score()` to calculate the marginal distribution score:\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "def get_fidelity_score(source, source_dataset_properties, syn):\n",
    "    source = copy.deepcopy(source)\n",
    "    syn = copy.deepcopy(syn)\n",
    "\n",
    "    columns_to_drop = [source_dataset_properties.session_key]\n",
    "    source.table = source.table.drop_columns(columns_to_drop)\n",
    "\n",
    "    columns_to_drop = [\"session_key\"]\n",
    "    syn.table = syn.table.drop_columns(columns_to_drop)\n",
    "\n",
    "    categorical_measurements = source_dataset_properties.filter_fields(\n",
    "        ftype=FieldType.MEASUREMENT, etype=EncoderType.CATEGORICAL\n",
    "    )\n",
    "\n",
    "    return marginal_dist_score(\n",
    "        source,\n",
    "        syn,\n",
    "        metadata=source_dataset_properties.metadata_fields,\n",
    "        other_categorical=categorical_measurements,\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNMp4sEeq2oT",
    "outputId": "6e2a69f5-5104-4692-c4ab-e02d6f08a114",
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:42.913522Z",
     "start_time": "2024-12-13T18:29:42.879236Z"
    }
   },
   "source": [
    "get_fidelity_score(\n",
    "    source=dataset, source_dataset_properties=dataset_properties, syn=syn\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7143160127325423"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the actions look good, we can use them for setting up the always-on workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:42.933619Z",
     "start_time": "2024-12-13T18:29:42.931552Z"
    }
   },
   "source": [
    "rec_actions"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rockfish.actions.dg.TrainTimeGAN at 0x31420f3e0>,\n",
       " <rockfish.actions.dg.GenerateTimeGAN at 0x3143bef00>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:42.952790Z",
     "start_time": "2024-12-13T18:29:42.951176Z"
    }
   },
   "source": [
    "train_actions = rec_actions[:-1]\n",
    "generate_actions = rec_actions[-1:]"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set up an always-on workflow for continuous data ingestion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employ the DataStreamLoad action to keep the workflow always on\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:43.030173Z",
     "start_time": "2024-12-13T18:29:42.957215Z"
    }
   },
   "source": [
    "# reduce the batch size for the following ingested data stream as the batch\n",
    "# size should be smaller than the number of sessions in the dataset\n",
    "train_actions[0].config().doppelganger.batch_size = 14\n",
    "stream = ra.DatastreamLoad()\n",
    "\n",
    "builder = rf.WorkflowBuilder()\n",
    "builder.add(stream, alias=\"input\")\n",
    "builder.add_path(*train_actions, parents=[\"input\"], alias=\"train_actions\")\n",
    "ingest_workflow = await builder.start(conn)\n",
    "print(f\"Ingestion Workflow ID: {ingest_workflow.id()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion Workflow ID: 1gwjqafjEcJGrn8HQxEz1B\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the data files to the workflow stream\n",
    "\n",
    "- each input is a dataset\n",
    "- each output is a trained model stored to the model_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data files to the workflow stream\n",
    "\n",
    "Replace the workflow ID with the actual workflow ID of the workflow that was set up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the sample files for the datastream workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:44.319515Z",
     "start_time": "2024-12-13T18:29:43.040553Z"
    }
   },
   "source": [
    "%%capture\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-2.csv\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-3.csv\n",
    "!wget --no-clobber https://docs.rockfish.ai/tutorials/finance-4.csv"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734114583.042544 3278498 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1734114583.458729 3278498 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1734114583.923510 3278498 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the workflow ID with the ID of the workflow that was just set up.\n",
    "\n",
    "This also allows you to run the data-ingestion service in an independent process.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:29:44.394565Z",
     "start_time": "2024-12-13T18:29:44.332382Z"
    }
   },
   "source": [
    "# Retrieve the workflow with the previous ID without need to re-build the workflow\n",
    "workflow_id = ingest_workflow.id()  # insert workflow ID here\n",
    "workflow = await conn.get_workflow(workflow_id)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:30:16.784761Z",
     "start_time": "2024-12-13T18:29:44.405420Z"
    }
   },
   "source": [
    "for file_num in range(2, 5):\n",
    "    data = rf.Dataset.from_csv(\"finance\", f\"finance-{file_num}.csv\")\n",
    "    await workflow.write_datastream(\n",
    "        \"input\", data\n",
    "    )  # \"input\" is the pre-set alias of the datastream\n",
    "    print(f\"Writing finance-{file_num} to datastream...\")\n",
    "    time.sleep(10)\n",
    "await workflow.close_datastream(\n",
    "    \"input\"\n",
    ")  # \"input\" is the pre-set alias of the datastream"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing finance-2 to datastream...\n",
      "Writing finance-3 to datastream...\n",
      "Writing finance-4 to datastream...\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:30:35.957341Z",
     "start_time": "2024-12-13T18:30:16.797330Z"
    }
   },
   "source": [
    "# check the status of the workflow\n",
    "async for log in workflow.logs():\n",
    "    print(log)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13T18:30:21Z input: INFO Read batch with 8850 rows from datastream\n",
      "2024-12-13T18:29:45Z train_actions: WARN Unsafe time cast on timestamp\n",
      "2024-12-13T18:30:32Z input: INFO Read batch with 9080 rows from datastream\n",
      "2024-12-13T18:29:46Z train_actions: INFO Starting DG training job\n",
      "2024-12-13T18:30:43Z input: INFO Read batch with 6979 rows from datastream\n",
      "2024-12-13T18:29:56Z train_actions: INFO Epoch 1 completed.\n",
      "2024-12-13T18:30:05Z train_actions: INFO Epoch 2 completed.\n",
      "2024-12-13T18:30:14Z train_actions: INFO Epoch 3 completed.\n",
      "2024-12-13T18:30:53Z train_actions: WARN Unsafe time cast on timestamp\n",
      "2024-12-13T18:30:53Z train_actions: INFO Starting DG training job\n",
      "2024-12-13T18:30:23Z train_actions: INFO Epoch 4 completed.\n",
      "2024-12-13T18:31:02Z train_actions: INFO Epoch 1 completed.\n",
      "2024-12-13T18:30:31Z train_actions: INFO Epoch 5 completed.\n",
      "2024-12-13T18:31:10Z train_actions: INFO Epoch 2 completed.\n",
      "2024-12-13T18:30:35Z train_actions: ERROR Internal error occurred while running the action. Please contact support@rockfish.ai\n",
      "2024-12-13T18:31:12Z train_actions: ERROR Workflow was stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/var/folders/l6/wcg2vb1x7_jc7_64xpyxpcsm0000gn/T/ipykernel_19167/3409177271.py\", line 3, in <module>\n",
      "  |     await workflow.wait(raise_on_failure=True)\n",
      "  |   File \"/Users/deepanshu/rockfish/public_tutorials/venv/lib/python3.12/site-packages/rockfish/remote/workflow.py\", line 216, in wait\n",
      "  |     raise WorkflowExceptionGroup(excs)\n",
      "  | rockfish.errors.WorkflowExceptionGroup: errors while running workflow (2 sub-exceptions)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | rockfish.errors.ActionError: Internal error occurred while running the action. Please contact support@rockfish.ai\n",
      "    +---------------- 2 ----------------\n",
      "    | rockfish.errors.ActionError: Workflow was stopped\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Add custom labels to the models that are generated\n",
    "\n",
    "These labels can be used later to filter models based off custom parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:30:36.101597Z",
     "start_time": "2024-12-13T18:30:35.967727Z"
    }
   },
   "source": [
    "usage = [\"experimental\", \"staging\", \"production\"]\n",
    "i = 0\n",
    "async for model in conn.list_models(labels={\"workflow_id\": workflow_id}):\n",
    "    await model.add_labels(conn, usage=usage[i])\n",
    "    i += 1"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate synthetic data using the trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide query params to the model_store search to get appropriate models as response\n",
    "\n",
    "This can be used if the models trained were previously tagged, the default label that exists is 'workflow_id' which is the id of the workflow that trained the model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:30:36.180287Z",
     "start_time": "2024-12-13T18:30:36.106879Z"
    }
   },
   "source": [
    "async for model in conn.list_models(labels={\"usage\": \"production\"}):\n",
    "    print(model)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model from the list of queried models and fetch it from remote\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T18:30:36.330208Z",
     "start_time": "2024-12-13T18:30:36.185898Z"
    }
   },
   "source": [
    "model = await rf.Model.from_id(\n",
    "    conn,\n",
    "    model.id,  # insert model id here of the filtered model after querying\n",
    ")\n",
    "print(model)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m rf\u001B[38;5;241m.\u001B[39mModel\u001B[38;5;241m.\u001B[39mfrom_id(\n\u001B[1;32m      2\u001B[0m     conn,\n\u001B[0;32m----> 3\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mid,  \u001B[38;5;66;03m# insert model id here of the filtered model after querying\u001B[39;00m\n\u001B[1;32m      4\u001B[0m )\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(model)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide the model and the synthesis config to a workflow to generate a synthetic dataset as the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow ID: 4P0fla7gp6MU85Tqx5DuyQ\n"
     ]
    }
   ],
   "source": [
    "builder = rf.WorkflowBuilder()\n",
    "builder.add(model)\n",
    "builder.add(*generate_actions, parents=[model], alias=\"gen\")\n",
    "builder.add(ra.DatasetSave(name=\"syn_data\"), parents=[\"gen\"])\n",
    "workflow = await builder.start(conn)\n",
    "print(f\"Workflow ID: {workflow.id()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02T01:10:13Z dataset-save: INFO using field 'session_key' to concatenate tables\n",
      "2024-11-02T01:10:13Z dataset-save: INFO Saved dataset 'BC4sYkI65pgGwZ2QctElx' with 35068 rows\n",
      "2024-11-02T01:09:58Z gen: INFO Downloading model with model_id='c00744e0-98a8-11ef-a2bf-7af83af06a78'...\n",
      "2024-11-02T01:10:11Z gen: INFO Generating 200 sessions...\n"
     ]
    }
   ],
   "source": [
    "async for log in workflow.logs():\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>fraud</th>\n",
       "      <th>session_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-06 23:59:38.418</td>\n",
       "      <td>5163.387593</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>M1946091778</td>\n",
       "      <td>fashion</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-07 20:43:36.007</td>\n",
       "      <td>6987.574420</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>M732195782</td>\n",
       "      <td>leisure</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-06 00:13:24.170</td>\n",
       "      <td>1.165829</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>M349281107</td>\n",
       "      <td>contents</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-07 07:06:30.770</td>\n",
       "      <td>4697.402428</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>M480139044</td>\n",
       "      <td>wellnessandbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06 13:44:56.971</td>\n",
       "      <td>106.728580</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>M349281107</td>\n",
       "      <td>wellnessandbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>2023-01-07 01:01:53.614</td>\n",
       "      <td>403.839851</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>M2122776122</td>\n",
       "      <td>hyper</td>\n",
       "      <td>0</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35064</th>\n",
       "      <td>2023-01-06 04:17:57.393</td>\n",
       "      <td>6550.755616</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>M1649169323</td>\n",
       "      <td>wellnessandbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35065</th>\n",
       "      <td>2023-01-06 06:36:17.908</td>\n",
       "      <td>6514.552014</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>M1649169323</td>\n",
       "      <td>leisure</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35066</th>\n",
       "      <td>2023-01-06 08:54:38.501</td>\n",
       "      <td>6511.151229</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>M1649169323</td>\n",
       "      <td>wellnessandbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>2023-01-07 00:33:54.034</td>\n",
       "      <td>3425.767440</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M349281107</td>\n",
       "      <td>contents</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35068 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp       amount age gender     merchant  \\\n",
       "0     2023-01-06 23:59:38.418  5163.387593   5      M  M1946091778   \n",
       "1     2023-01-07 20:43:36.007  6987.574420   4      M   M732195782   \n",
       "2     2023-01-06 00:13:24.170     1.165829   0      E   M349281107   \n",
       "3     2023-01-07 07:06:30.770  4697.402428   1      F   M480139044   \n",
       "4     2023-01-06 13:44:56.971   106.728580   5      M   M349281107   \n",
       "...                       ...          ...  ..    ...          ...   \n",
       "35063 2023-01-07 01:01:53.614   403.839851   2      F  M2122776122   \n",
       "35064 2023-01-06 04:17:57.393  6550.755616   0      E  M1649169323   \n",
       "35065 2023-01-06 06:36:17.908  6514.552014   0      E  M1649169323   \n",
       "35066 2023-01-06 08:54:38.501  6511.151229   0      E  M1649169323   \n",
       "35067 2023-01-07 00:33:54.034  3425.767440   0      M   M349281107   \n",
       "\n",
       "                category  fraud  session_key  \n",
       "0                fashion      1          0.0  \n",
       "1                leisure      1          1.0  \n",
       "2               contents      1          2.0  \n",
       "3      wellnessandbeauty      0          3.0  \n",
       "4      wellnessandbeauty      0          4.0  \n",
       "...                  ...    ...          ...  \n",
       "35063              hyper      0        197.0  \n",
       "35064  wellnessandbeauty      0        198.0  \n",
       "35065            leisure      0        198.0  \n",
       "35066  wellnessandbeauty      0        198.0  \n",
       "35067           contents      0        199.0  \n",
       "\n",
       "[35068 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_data = await workflow.datasets().concat(conn)\n",
    "syn_data.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
